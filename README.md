# Facial-Sensing Smart Glasses for Mobile Monitoring of Digital Biomarkers of Depression

This repository contains the code and data associated with the study *Facial-Sensing Smart Glasses for Mobile Monitoring of Digital Biomarkers of Depression*. The analysis focuses on automatic facial configurations captured during a video-viewing task, where participants were exposed to emotionally evocative videos (positive, negative, or neutral). It includes validation of the model for detecting facial configurations from spontaneous facial movements, as well as analysis of group-level differences in potential digital biomarkers of depression. The repository provides access to the trained model, prediction outputs, and a sample of the feature data.

## Data

All shared data is located in the `data` directory and includes:

- `sample_data.py` – Contains sample feature data. To request access to the full feature dataset, please contact the corresponding author at [borjan.sazdov@emteqlabs.com](mailto:borjan.sazdov@emteqlabs.com).
- `predictions.csv` – Model predictions generated from the input features.
- `intensities.csv` – Estimated expression intensities for the predicted facial configurations. These intensities were derived from raw sensor data prior to segmentation and feature extraction. Due to confidentiality, we are unable to share the full preprocessing pipeline used to compute intensity values.

## Model
To access the pre-trained machine learning model for facial configuration detection please contact the corresponding author at [borjan.sazdov@emteqlabs.com](mailto:borjan.sazdov@emteqlabs.com).

## Repo structure

```
.
├── README.md                                           # This file
└── data                                                # Shared data
    └── sample_data.csv                                 # Sample features data
    └── predictions.csv                                 # Predictions generated by the model on the full feature set
    └── intensities.csv                                 # Dataframe with intensities for each expression calculated on the raw data
└── utils                                               # Helper functions for processing and analysis
    └── count.py                                        # Functions for calculating facial configuration frequency biomarker
    └── duration.py                                     # Functions for calculating facial configuration duration biomarker
    └── intensity.py                                        # Functions for calculating facial configuration intensity biomarker
├── analysis.ipynb                                      # Notebook for data analysis
├── requirements.txt                                    # Package dependencies
├── .gitignore                                          # .gitignore file
```

## Usage

Create a new Python environment, for example with conda:
```
conda create -n [environment_name]
conda activate [environment_name]
conda install python=3.11
```
Then install the requirements, using `pip install -r requirements.txt`.

Run the `analysis.ipynb` notebook to obtain the results.